{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf83102",
   "metadata": {},
   "source": [
    "# Contents \n",
    "\n",
    "### [1. What is Machine Learning ?](#1.-What-is-Machine-Learning?)\n",
    "\n",
    "### [2. AI vs ML vs DL vs DS](#2.--AI-vs-ML-vs-DL-vs-DS)  \n",
    "\n",
    "### [3. Supervised, Unsupervised and Reinforcement Machine Learning](#3.-Supervised,-Unsupervised-and-Reinforcement-Machine-learning)   \n",
    "\n",
    "### [4. Supervised Machine Learning Algorithms](#4.-Supervised-Machine-Learning-algorithms)    \n",
    "\n",
    "### [4.1 Regression Algorithms](#4.1-Regression-algorithms)          \n",
    "-  [Linear Regression](#Linear-Regression)  \n",
    "    - [Linear Equation](#Linear-Equation)\n",
    "    - [Cost Function](#Cost-function)\n",
    "    - [Gradient Descent](#Gradient-Descent)\n",
    "    - [Assumptions of Linear Regression](#Assumptions-of-linear-regression)                \n",
    "- [Lasso and Ridge Regression](#Lasso-[L1]-and-Ridge-[L2]-regularization)             \n",
    "                           \n",
    "### [4.2 Classification Algorithms](#4.2-Classification-algorithms)          \n",
    "- [Logistic Regression](#Logistic-Regression)  \n",
    "   - [Sigmoid Function](#Sigmoid-Function)  \n",
    "   - [Cost Function](#Cost-Function)\n",
    "   - [Convergence Algorithm](#Convergence-Algorithm)    \n",
    "- [Naive Bayes](#Naive-Bayes)   \n",
    "\n",
    "### [4.3 Regression and Classification algorithms](#Regression-and-Classification-Algorithms)\n",
    "- [KNN](#KNN)  \n",
    "   - [KNN Classification](#KNN-Classification)\n",
    "       - [Distance Measures](#Distance-Measures)\n",
    "   - [KNN Regression](#KNN-Regression)  \n",
    "- [Decision Tree](#Decision-Tree)\n",
    "   - [Decision Tree Classification](#Decision-Tree-Classification)\n",
    "       - [Calculation of Purity](#Calculation-of-purity)\n",
    "       - [Information Gain](#Information-Gain)\n",
    "   - [Decision Tree Regression](#Decision-Tree-Regression)\n",
    "       - [Disadvantages](#Disadvantages-of-Decision-tree-in-regression-problems)    \n",
    "- [Ensemble Techniques](#Ensemble-Techniques)\n",
    "   - [Bagging](#Bagging)\n",
    "       - [Random Forest classification](#Random-Forest-Classification)\n",
    "       - [Random Forest Regression](#Random-Forest-Regression)\n",
    "   - [Boosting](#Boosting)\n",
    "       - [Ada Boost classification and Regression](#1.-Ada-Boost)\n",
    "       - [Gradient Boosting classfication and Regression](#2.-Gradient-Boosting)\n",
    "       - [XG Boost](#3.-XG-Boost)\n",
    "           - [XG Boost Classification](#XG-Boost-Classification)\n",
    "           - [XG Boost Regression](#XG-Boost-Regression)  \n",
    "- [Support Vector Machine Classification and Regression (SVM)](#Support-Vector-Machine[SVM])\n",
    "    - [SVM Intution](#SVM-Intution)  \n",
    "      \n",
    "\n",
    "    \n",
    "### [5. Unsupervised Machine Learning Algorithms](#5.-Unsupervised-Machine-Learning-algorithms)\n",
    "- [K means Clustering](#-K-means-Clustering)  \n",
    "  \n",
    "- [Hierarchical Clustering](#-Hierarchical-Clustering)  \n",
    "   \n",
    "- [DB Scan](#-DB-Scan)\n",
    "\n",
    "### [6. Dimensionality Reduction](#6.--Dimensionality-Reduction)\n",
    "- [Principle Component Analysis](#-Principle-Component-Analysis)    \n",
    "   \n",
    "### [7. Performance Metrics](#7.--Performance-Metrics)  \n",
    "  \n",
    "### [7.1 Supervised ML Metrics](#7.1--Supervised-ML-Metrics)\n",
    "- [Performance Metrics for Regression Problems](#Performance-Metrics-for-Regression-Problems)  \n",
    "- [Performance Metrics for Classification Problems](#Performance-Metrics-for-Classification-Problems)  \n",
    "\n",
    "### [7.2 Unsupervised ML Metrics](#7.2--Unsupervised-ML-Metrics)\n",
    "- [Performance Metrix for Unsupervised ML Problems](#Performance-metrix-for-Unsupervised-ML-Problems)\n",
    "\n",
    "### [8. Bias and Variance](#8.--Bias-and-Variance)"
   ]
  },
  {
   "attachments": {
    "image4-1-5.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "e7874752",
   "metadata": {},
   "source": [
    "# 1. What is Machine Learning?\n",
    "- Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "- It enables computers to learn automatically from past data. Machine learning uses various algorithms for building mathematical models and making predictions using historical data or information.  \n",
    "&nbsp;  \n",
    "### Traditional Programming\n",
    "- In Taditional programming the user gives an input, a program to a computer and then it provides output (basically an answer for the input).  \n",
    "- Here the focus is to generate an answer (output) by building or writing a program or a code.\n",
    "&nbsp;  \n",
    "### Machine Learning\n",
    "- But in Machine learning the user provides an input and an output to a computer and then the computer provides a model as its ouput.\n",
    "- Here the focus is to build a model using machine learning algorithms and an input (data).  \n",
    "&nbsp;  \n",
    "![image4-1-5.png](attachment:image4-1-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9febb",
   "metadata": {},
   "source": [
    "# 2.  AI vs ML vs DL vs DS\n",
    "\n",
    "<img src = 'Data-Science-1-2.png.png' height = 800 width = 650>\n",
    "\n",
    "### Artificial Intelligence \n",
    "- AI involves building smart machines capable of performing tasks that require human intelligence.\n",
    "- Building AI applications, models, systems in a way they think and decide like humans.\n",
    "- When given a problem to a AI application or a machine they are able to solve the problem with higher accuracy without the need of human involvement.   \n",
    "<img src = 'AI-21.png' height=800 width=650>\n",
    "\n",
    "### Machine Learning\n",
    "- Machine Learning is a subset of AI which involves algorithms and statistical models that helps in training machines.\n",
    "- ML helps in building AI systems or models by training and making predictions using algorithms and lines of codes.\n",
    "<img src = 'Untitled-design-18-1.png' height=800 width=650>\n",
    "\n",
    "### Deep Learning\n",
    "- Deep learning is a subset of ML in which multi-layered structure of algorithms called neural networks will be used to train models.\n",
    "- Deep learning is a method that teaches computers to process data in a way that is inspired by human brain.\n",
    "- DL algorithms also required data to learn and solve problems.\n",
    "- DL models can recognize complex patterns in pictures, text, sounds and other kinds of data to find insights and make predictions.\n",
    "\n",
    "\n",
    "### Data Science\n",
    "- Data Science is a multi disciplinary field that includes various technologies and methods such as computer science, programming and statistics, mathematics and domain knowledge.\n",
    "- The main goal of data science is to use technical and statistical methods to find trends, patterns, insights from data and also make various predictions.\n",
    "- Data Scientists help companies and business to making better decisions through these insights.\n",
    "<img src = 'DS-1.png' height = 800 width = 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64a5c2",
   "metadata": {},
   "source": [
    "[Go to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3fa692",
   "metadata": {},
   "source": [
    "# 3. Supervised, Unsupervised and Reinforcement Machine learning \n",
    "\n",
    "<img src = '22.png' height = 800 width = 650>\n",
    " \n",
    "# Supervised Machine learning  \n",
    "- Supervised Machine Learning is when the model gets trained under supervision.   \n",
    "- Supervised ML involves training and testing model using labelled data. The data contains input(independent features) and output(dependent features).   \n",
    "- Machine Learning algorithms predicts the output based on the data it gets trained on.  \n",
    "- Under Supervised ML  we have two kinds of problems \n",
    "    1. Regression\n",
    "    2. Classification\n",
    "   ## Regresssion\n",
    "     - When the target variable is continuous then the problem is a regression problem. And we use regression algorithms to solve the problem or train the model.\n",
    "    \n",
    "   ## Classification\n",
    "     - When the target variable is categorical then the problem is a classification problem. And we use classification algorithms to solve the problem.\n",
    "     - 2 Class categories = Binary Classification\n",
    "     - More than 2 classes = Multi-class classification \n",
    "<img src = 'Regression_vs_classification.png' height = 800 width = 650>  \n",
    "  \n",
    "&nbsp;  \n",
    "# Unsupervised Machine learning       \n",
    "- In Unsupervised machine learning we give unlabelled data to the model. The data only contains input features and no output features.\n",
    "- Here we dont predict anything but our motive is to determine patterns, trends, insights from the data.\n",
    "- Under Unsupervised ML we have \n",
    "    1. clustering\n",
    "    2. Dimensionality Reduction\n",
    "    \n",
    "    ## Clustering\n",
    "     - Involves forming clusters / groups based on similar patterns, characteristics, properties.\n",
    "     - The motive is to group the datapoints based on similar characteristics. \n",
    "        <img src = 'clustering.png' height = 800 widht = 650>\n",
    "    ## Dimensionality Reduction  \n",
    "     - Reducing the number of features in a dataset to improve model's accuracy and efficieny.\n",
    "     - Higher Dimension to lower dimension.\n",
    "  \n",
    "# Reinforcement Learning\n",
    "- In reinforcement learning we train model based on rewarding desired actions/behaviors  or punishing undesired ones.\n",
    "- Is is a feedback-based Machine learning technique in which an agent learns to behave in an environment by performing the actions and seeing the results of actions. \n",
    "- For each good action, the agent gets positive feedback, and for each bad action, the agent gets negative feedback or penalty.\n",
    "<img src = 'reinffo.png' height = 400 width = 650>          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8bfaa6",
   "metadata": {},
   "source": [
    "[Go to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe23d2",
   "metadata": {},
   "source": [
    "# 4. Supervised Machine Learning algorithms\n",
    "\n",
    "# 4.1 Regression algorithms\n",
    "- Regression algorithms are a subset of supervised machine learning algorithms that is primarly used for predicting or estimating a continuous variable. \n",
    "- The goal of regression algorithm is to create a model that can accurately predict the numeric value of the dependent variable based on the independent variable.\n",
    "- Regression algorithm are used specifically when dealing with continuous variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca1658",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "- Linear regression is used to model the relationship between dependent and independent variables by fitting a best fit line. \n",
    "- The goal is to find the best fit line that minimizes the difference between the predicted values and the actual values [error].\n",
    "- The distance between the line and the datapoints should be minimum.\n",
    "\n",
    "&nbsp;  \n",
    "<img src = 'linear reg.png' height = 800 width = 650>\n",
    "  \n",
    "&nbsp;  \n",
    "## Linear Equation\n",
    "Some of the common linear equations used in linear regression are : \n",
    ">><font color = orange>**y = mx + c**</font> \n",
    "- y = dependent variable\n",
    "- m = intercept\n",
    "- x = independent variable\n",
    "- c = slope\n",
    "\n",
    ">><font color = orange>**y= β0 + β1(x)**</font>\n",
    "- y = dependent variable\n",
    "- β0 = intercept\n",
    "- β1 = slope\n",
    "- x = independent variable\n",
    "\n",
    ">><font color = orange>**hθ(x) = θ0 + θ1(x)**</font>\n",
    "- hθ (x) = dependent variable\n",
    "- θ0 = intercept\n",
    "- θ1 = slope\n",
    "- x = independent variable\n",
    "  \n",
    "&nbsp;  \n",
    "<img src = 'line_equa.jpg' height = 800 width = 650 >   \n",
    "\n",
    "&nbsp;  \n",
    "- Here the θ0 = 0 (intersept = 0) when x = 0. \n",
    "    - when x = 0\n",
    "    - hθ (x) = θ0\n",
    "    - Therefore θ0 = 0 and <font color = green>**intersept = 0**</font>.\n",
    "    \n",
    "&nbsp;  \n",
    "## How do we find the best fit line ? \n",
    "- To find the best fit line we need to draw multiple lines randomly and we need to find the error [MSE] for each line. \n",
    "- The line that has the lowest error is our best fit line. \n",
    "\n",
    "&nbsp;    \n",
    "<img src = 'Line-of-Best-fit-1.png' height = 800 width = 650>\n",
    "\n",
    "&nbsp;  \n",
    "- In the above image there are 5 random fit lines and the line with the lowest error is our best fit line. \n",
    "- As an example we have drawn 5 lines but in real world scenarios we would have to draw 100, 200 or even 1000 lines to find the best fit line.\n",
    "- **<font color = red>But the question raises for how many times we have to draw the line ?</font>** It can be for 1000 times or 10000 times even infinite times. \n",
    "- To find how many times we have to draw lines we need to \n",
    ">><font color = lime>Start at one point and it should lead towards the best fit line</font> \n",
    "    \n",
    "<img src = 'point.png' height = 800 width = 650>    \n",
    "&nbsp;    \n",
    "  \n",
    "- To do this we use **<font color = blue>Cost function</font>**.\n",
    "\n",
    "&nbsp;  \n",
    "## Cost function\n",
    "<img src = 'cost_function.png' heigth = 800 width = 650>  \n",
    "  \n",
    "- Our motive here is to use cost function to determine the best fit line with minimal error (MSE).  \n",
    "- We need to find J(θ1) for different data points and for different θ1(slope) values. \n",
    "    - Data points (1,1)\n",
    "                  (2,2)\n",
    "                  (3,3)  \n",
    "&nbsp;               \n",
    "    1. Assuming θ0 = 0, θ1 = 1  \n",
    "       Applying the formula hθ(x) = θ1(x) we will get 1, 2, 3   \n",
    "       Now applying cost function and we will get J(θ1) = 0.    \n",
    "&nbsp;           \n",
    "    2. Similarly assuming θ0 = 0, θ1 = 0.5  \n",
    "       we will get J(θ1) = 0.58  \n",
    "&nbsp;         \n",
    "    3. Assuming  θ0 = 0, θ1 = 0  \n",
    "       we will get J(θ1) = 2.3  \n",
    "&nbsp;   \n",
    "    4. Assuming θ0 = 0, θ1 = 2  \n",
    "       we will get J(θ1) = 2.3  \n",
    "&nbsp;         \n",
    "    5. Assuming θ0 = 0, θ1 = 2.5  \n",
    "       we will get J(θ1) = 5.25  \n",
    "&nbsp;       \n",
    "- Now plotting all the J(θ1) we will get a cost function graph which looks like this\n",
    "- The graph is also know as <font color = blue>**Gradient Descent**</font>. \n",
    "\n",
    "&nbsp;  \n",
    "## Gradient Descent  \n",
    "<img src = 'gradient descent.png' heigth = 700 width = 500>     \n",
    "&nbsp;    \n",
    "&nbsp;  \n",
    "  \n",
    "- While applying the cost function we assume θ0 and θ1 but **<font color = red>at which value should we assume for θ0, θ1 and for how many times we should be assuming</font>**.\n",
    "- Well for that issue we use <font color = blue>**Gradient descent algorithm / convergence algorithm**</font>.   \n",
    "  \n",
    "&nbsp;  \n",
    "## Gradient Descent algorithm  \n",
    "  \n",
    "<img src = 'convergence 1.png' height = 400 width = 350>    \n",
    "The convergence will stop as we move close to global minimum.  \n",
    "  \n",
    "&nbsp;          \n",
    "**The working of convergence algorithm :**    \n",
    "  \n",
    "&nbsp;    \n",
    "<img src = 'posi and nega slop.png' height = 800 width = 650>\n",
    "\n",
    "&nbsp;  \n",
    "### 1. Negative Slop\n",
    " - Suppose I start at negative slop to reach the global minimum I would have to increase the θ1. Inorder to reach the global minimum the convergence algorithm will look like this\n",
    ">> <font color =orange>**(-ve) * (-ve) is positive.**</font>\n",
    "    - First -ve is in convergence algorithm and the next -ve is the value of the slop.\n",
    "      \n",
    "&nbsp;      \n",
    "  \n",
    "### 2. Positive slop \n",
    " - Suppose I start at positive slop to reach the global minimul I would have to decrease teh θ1. The convergence alorithm will look like this\n",
    ">> <font color =orange>**(-ve) * (+ve) is negative.**</font>\n",
    "    - First -ve is in convergence algorithm and the +ve is the value of the slop.\n",
    " \n",
    "&nbsp;  \n",
    "## Learning rate in convergence algorithm [  α  ]\n",
    "- The alpha α in the convergence algorithm refers to the learning rate.\n",
    "- Learning rate defines at what speed we will reach the global minimum.\n",
    "  \n",
    "&nbsp;  \n",
    "<img src = 'Learning rate.png' height = 800 width = 650>\n",
    "    \n",
    "### 1. α = Huge  \n",
    "If α = Huge, gradient descent end up passing through global minimum. It will keep on reflecting the slop and may never reach the global minimum.  \n",
    "&nbsp;      \n",
    "### 2. α = Small / moderate  \n",
    "If α = Small / moderate value we will slowly reach the global minimum.  \n",
    "\n",
    "&nbsp;  \n",
    "## Local and Global Minima\n",
    "<img src = 'global.png' height = 800 width = 650>\n",
    "\n",
    "&nbsp;  \n",
    "- Local minima represent the lowest point in a specific region. The algorithm might confuse local minima for global minima.\n",
    "- Since slope in local minima is 0 (θ1 = 0) what happens when we get stuck in local minima ?\n",
    "- When we use convergence algorithm we will never get stuck in local minima.\n",
    "\n",
    "&nbsp;  \n",
    "# Assumptions of linear regression\n",
    "  \n",
    "**1. Linearity :**\n",
    "    There must be a linear relationship between the independent and dependent variable. This means that changes in dependent variable are directly propostional to the changes in the independent variable.  \n",
    "&nbsp;      \n",
    "**2. Normal Distribution:**  \n",
    "    Linear regression assumes that the data is normal distributed. It also means that the residuals (difference between predicted and actual values) must follow normal distribution. Only then the model performs well.  \n",
    "&nbsp;        \n",
    "**3. Standardization:**   \n",
    "    Since gradient descent is involved the model assumes that the data is standardized using z-score. μ = 0, σ = 1. Therefore we need to standardize the data.  \n",
    "&nbsp;        \n",
    "**4. No / little multi collinearity:**  \n",
    "    Multi collinearity refers to strong correlation between the independent variable. High collinearity makes it difficult to determine the individual effect of each variable on the dependent variable.\n",
    "    \n",
    "&nbsp;   \n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3dd9f5",
   "metadata": {},
   "source": [
    "# Lasso [L1] and Ridge [L2] regularization\n",
    "- Lasso/ridge regularization are often used interchangebally with lasso/ridge regression in the context of linear regression. These terms refer to the same concept of regularizing a model by preventing overfitting.  \n",
    "&nbsp;  \n",
    "**The image shows the comparison between the best fit lines of lasso, ridge, linear regression.**\n",
    "<img src = 'las and rid.png' height = 600 width = 550>  \n",
    "\n",
    "# Lasso [L1] regularization\n",
    "- Lasso stands for <font color = green>**Least Absolute and Selection Operator.**</font>\n",
    "- Lasso regularization, also known as L1 regularization, is a technique used in machine learning and linear regression to prevent overfitting and improve the generalization performance of models.\n",
    "- L1 does this but adding a penalty term to the linear regression's cost function. The penalty contains a lambda λ which is a hyperparameter and absolute value of slope |slope| or absolute of value of coefficients (both are same).\n",
    "<img src = 'Lasso.png' height = 800 width = 850>\n",
    "  \n",
    ">**λ is a hyperparameter that controls the amount of regularization applied.**\n",
    "During hyperparameter tunning we need to assign number of iterations for λ. It is of no use if the iterations are 0.\n",
    "   \n",
    "&nbsp;  \n",
    "<img src = 'lasso 2.png ' height = 800 width = 850>\n",
    "&nbsp;  \n",
    "1. **Objective function:** The objective of LASSO regression is to find the values of the coefficients that minimize the sum of the squared differences between the predicted values and the actual values, while also minimizing the L1 regularization RSS + L₁ Where: RSS is the residual sum of squares, which measures the error between the predicted values and the actual values.  \n",
    "&nbsp;    \n",
    "2. **Shrinking coefficients:** LASSO regression can shrink the coefficients towards zero. When λ is sufficiently large, some coefficients are driven to exactly zero. This property of LASSO makes it useful for feature selection, as the variables with zero coefficients are effectively removed from the model. Which ever feature is not performing well the θ value or slope value will be very very small. Its like the feature is neglected.  \n",
    "&nbsp;    \n",
    "3. **Tuning parameter λ:** The choice of the regularization parameter λ is crucial in LASSO regression. A larger λ value increases the amount of regularization, leading to more coefficients being pushed towards zero. Conversely, a smaller λ value reduces the regularization effect, allowing more variables to have non-zero coefficients.  \n",
    "&nbsp;    \n",
    "4. **Uses :**\n",
    "    1. prevent overfitting\n",
    "    2. perform feature selection  \n",
    "&nbsp;    \n",
    "# Ridge [L2] regularization\n",
    "- Ridge regularization is similar to lasso regularization which pervents overfitting by adding a penalty to the cost function of a linear regression model. \n",
    "- However the penalty is a bit different from that of lasso's penalty. Look at the formula below\n",
    "<img src = 'Ridge.png' height = 800 width = 750>  \n",
    "<img src = 'Ridge 2.png' height = 600 width = 750>\n",
    "\n",
    "&nbsp;  \n",
    "1. **Shrinking Coefficients :** In the above equation, the penalty term regularizes the coefficients of the model, and hence ridge regression reduces the amplitudes of the coefficients that decreases the complexity of the model. As we can see from the above equation, if the values of λ tend to zero, the equation becomes the cost function of the linear regression model. Hence, for the minimum value of λ, the model will resemble the linear regression model.\n",
    "\n",
    "&nbsp;  \n",
    "Its better to use both L1 and L2 techniques and determine which one performs well.\n",
    "\n",
    "&nbsp;    \n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd03fc",
   "metadata": {},
   "source": [
    "# 4.2 Classification algorithms\n",
    "- Classification algorithms are a subset of supervised machine learning algorithm which is primaryly used to categorize or classify datapoints into different groups or classes.\n",
    "- Classification algorithms helps in building model that can classifiy a datapoint into predefined groups or classes.\n",
    "- These algorithms are used when dealing with categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c5657f",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "- Logistic regression as the name confuses is not a regression algorithm, it is a classification algorithm.\n",
    "- It is used to solve both binary and multi-class problems\n",
    "- Below is the graph of logistic regression \n",
    "<img src = 'logi ex.png' height = 800 width = 650>  \n",
    "- For a new data point the model will classify it as either 1 or 0 each represents a unique class.\n",
    "- Consider the following example:\n",
    "<img src = 'logi.png' heigth = 800 width = 650>  \n",
    "&nbsp;    \n",
    "\n",
    "><font color = red>**It looks similar to linear regression right? So why can't we use linear regression to solve the problem?**</font>  We can assign similar conditions like hθ(x) < 5 = Fail or 0 and similarly hθ(x) > 5 = Pass or 1.\n",
    "  \n",
    "&nbsp;    \n",
    "Well for that consider the following scenario  \n",
    "- What if the dataset contains outliers? Then the best fit line will look like this\n",
    "<img src = 'logi pro.png' heigth = 800 width = 650>    \n",
    "&nbsp;    \n",
    "- Since the dataset contains outliers the best fit line has be compromised as a result,\n",
    "    1. For datapoints 7, 8 the model has classified it as Fail which is wrong.\n",
    "    2. For datapoints 1, 2 the model struggles to classify as the best fit line goes beyond zero into the negative zone.\n",
    "    3. The best fit line goes greater than 1 in the y axis side. For data points 15, 16 the model struggles to classify as the moximum is 1.  \n",
    "&nbsp;      \n",
    "- <font color = blue>**To solve this problem the best fit line has to be squashed horizontally.**</font> Like the graph given below\n",
    "<img src = 'squashed.png' height = 800 width = 650>\n",
    "&nbsp;  \n",
    "- To squash the line we use <font color = blue>**Sigmoid Function**</font>.\n",
    "  \n",
    "&nbsp;    \n",
    "## Decision Boundry \n",
    "- A decision boundary is a line or curve that separates the data points into different classes in a classification problem. In logistic regression, the decision boundary is determined by the sigmoid/logistic function.\n",
    "- The logistic function is a sigmoid function that maps any real number to a value between 0 and 1. The logistic function is used to calculate the probability of a data point belonging to a particular class.  \n",
    "&nbsp;    \n",
    "## Sigmoid Function\n",
    "Deriving sigmoid function\n",
    "<img src = 'sigmoid.png' height = 800 width = 650>\n",
    "&nbsp;  \n",
    "Sigmoid function in graph\n",
    "<img src = 'sig graf.png' heigth = 800 width = 750>  \n",
    "&nbsp;   \n",
    "Applying sigmoid function\n",
    "<img src = 'apply sig.png' heigth = 800 width = 650>  \n",
    "\n",
    "&nbsp;  \n",
    "## Cost Function\n",
    "- In logistic regression the first best fit line will be determined using linear regression, then the squashing of line is done using logistic regression\n",
    "To find the best fit line we need to\n",
    "><font color = lime>Start at one point and it should lead towards the best fit line</font> \n",
    "  \n",
    "<img src = 'point.png' height = 600 width = 650>\n",
    "  \n",
    "><font color = blue>Therefore we need a cost function for logistic regression as well.</font>\n",
    "\n",
    "<img src = 'logi cost.png' height = 600 width = 600> \n",
    "  \n",
    "&nbsp;    \n",
    "### Non-convex and convex function \n",
    "  \n",
    "<img src = 'non convex.png' height = 800 width = 650>\n",
    "  \n",
    "- In a convex function there is only one global minima but in non-convex functions there are lot of local minima therefore <font color = red>we cannot reach the global minima if the above cost function is used.</font>  \n",
    "&nbsp;    \n",
    "## Valid Cost Function\n",
    "<img src = 'valid cost.png' height = 800 width = 650>  \n",
    "<img src = 'valid graph.png' heigth = 800 width = 650>\n",
    "&nbsp;  \n",
    "Writing cost functions in different way,\n",
    "<img src = 'final cost logi.png' height = 800 width = 650>  \n",
    "\n",
    "## Convergence Algorithm\n",
    "<img src = 'logi convergence.png' height = 500 width = 450>  \n",
    "Gradient descent / convergence algorithm will work the same way as it works in linear regression. The convergence will slow down as we move close to global minimum.\n",
    "\n",
    "&nbsp;  \n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd34e7f",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "- Naive bayes classifier is a probabilistic machine learning algorithm used for classification tasks.\n",
    "- The crux behind naive bayes is <font color = blue>**Bayes Theorem**.</font>   \n",
    "- **Naïve:** It is called Naïve because it assumes that the occurrence of a certain feature is independent of the occurrence of other features. Such as if the fruit is identified on the bases of color, shape, and taste, then red, spherical, and sweet fruit is recognized as an apple. Hence each feature individually contributes to identify that it is an apple without depending on each other.\n",
    "- **Bayes:** It is called Bayes because it depends on the principle of Bayes' Theorem.\n",
    "\n",
    "## Bayes Theorem\n",
    "<img src = 'bayes exp.png' height = 800 width = 500>    \n",
    "&nbsp;  \n",
    "Deriving bayes theorem\n",
    "<img src = 'bayes.png' height = 600 width = 600>\n",
    "\n",
    "### In what way Bayes Theorem is used in Naive Bayes?\n",
    "Consider the following example\n",
    "<img src = 'naive data.png' height = 800 width = 650>  \n",
    "<img src = 'naive data 2.png' height = 800 width = 450>\n",
    "<img src = 'naive data 3.png' height = 800 width = 450>\n",
    "<img src = 'naive data 4.png' height = 800 width = 450>\n",
    "<img src = 'naive example.png' height = 800 width = 750>\n",
    "  \n",
    "&nbsp;    \n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66be968",
   "metadata": {},
   "source": [
    "# Regression and Classification Algorithms\n",
    "- There are some machine learning algorithms which can be used for both regression and classification problems.\n",
    "\n",
    "# KNN\n",
    "\n",
    "# KNN Classification\n",
    "- K nearest neighbors (KNN) algorithm is a non-parametric algorithm, which means it does not make any assumptions about the distribution of the data.\n",
    "- KNN can be used for both regression and classification problems.\n",
    "<img src = 'knn.png' height = 800 width = 750>\n",
    "- Since blue is the maximum every datapoints in that group is considered as blue class.\n",
    "- The same goes for orange.\n",
    "\n",
    "**1. K-Nearest Neighbors:** The \"K\" in KNN represents the number of nearest neighbors to consider when making a classification decision. For each data point to be classified, KNN finds the K data points in the training dataset that are closest to it based on a distance metric (e.g., Euclidean distance).    \n",
    "&nbsp;  \n",
    "**2. Majority Voting:** Once the K nearest neighbors are identified, KNN uses a majority voting mechanism to assign a class label to the data point being classified. In other words, it counts how many of the K neighbors belong to each class and assigns the class label with the highest count.  \n",
    "&nbsp;  \n",
    "**3. Training:** KNN does not involve explicit training like many other algorithms. Instead, it stores the entire training dataset in memory for use during the prediction phase.   \n",
    "&nbsp;  \n",
    "**4. Prediction:** When a new data point is presented for classification, KNN identifies the K nearest neighbors to that data point from the training dataset. It calculates a weighted vote or a simple count of the class labels among these neighbors. The class label that receives the most votes becomes the predicted class label for the new data point.\n",
    "\n",
    "## Distance Measures\n",
    "- The calculation of distance between the datapoints is based on \n",
    "    1. Eucledian distance\n",
    "    2. Manhattan distance\n",
    "    3. Minkowski distance\n",
    "    4. Cosine distance\n",
    "    5. Hammning distance\n",
    "    \n",
    "## 1. Eucledian Distance (L2 norm)\n",
    "<img src = 'eucledian.png' height = 800 width = 650>\n",
    "\n",
    "- Eucledian distance is based on **pythagoras theorem.**\n",
    "- Pythagoras theorem calcuates the length of the hypoteneus of a right-angle.\n",
    "\n",
    ">> <font color = orange>**$AC^2$ = $AB^2$ + $BC^2$**</font> \n",
    "  \n",
    ">> <font color = orange>**AC =  $ \\sqrt{AB^2 + BC^2}$**</font> \n",
    "\n",
    "<img src = 'eucledian for.png' height = 800 width = 550> \n",
    "\n",
    "Suppose we have 3 dimensions \n",
    "- (x1 , y1) will become (x1, y1, z1)\n",
    "- (x2 , y2) will become (x2, y2, z2)\n",
    "  \n",
    "The formula will be \n",
    ">><font color = orange>**AB = $ \\sqrt{(x2 - x1)^2 + (y2 - y1)^2 + (z2 - z1)^2}$**</font>\n",
    " \n",
    "## 2. Manhattan Distance (L1 norm)\n",
    "<img src = 'manhattan.png' height = 800 width = 550>\n",
    "- Manhattan distance, also known as the city block distance or taxicab distance. Manhattan distance is similar to eculedian distance except it takes the absolute value of x and y.\n",
    "<img src = 'manhattan for.png' height = 800 width = 550>\n",
    "- While taking the absolute value if we get a -ve value ignore the -ve sign and take only the value.\n",
    "  \n",
    "Deciding which distance should use has to be decided using hyperparameter tunning or cross validation.\n",
    "&nbsp;  \n",
    "\n",
    "## 3. Minkowski Distance (Lp norm)\n",
    "-  Minkowski distance is the generalized form of the euclidean and Manhatten distance. Why do we call it to generalize? because we take both the distance technique and the new technique for finding the distance between vectors. It adds a parameter, called the “P“, that allows different distance measures to be calculated.\n",
    "<img src = 'minkowski for.png' height = 800 width = 550>  \n",
    "- The p value in the formula can be manipulated to give us different distances like:\n",
    "    1. p = 1, when p is set to 1 we get Manhattan distance\n",
    "    2. p = 2, when p is set to 2 we get Euclidean distance\n",
    "- Choosing the appropriate value of p is often done through experimentation and domain knowledge, as it can significantly affect the performance of the k-Nearest Neighbors (KNN) algorithm or other algorithms that use the Minkowski distance.\n",
    "\n",
    "## 4. Cosine distance \n",
    "- cosine distance or cosine similarity is often used as a measure of similarity between data points, particularly when dealing with high-dimensional data or text data. \n",
    "<img src = 'cosine distance.jpg' height = 800 width = 950>\n",
    "- The cosine similarity ranges from -1 to +1 where \n",
    "    - -1 (completely dissimilar) \n",
    "    -  1 (completely similar)\n",
    "    -  0 indicating orthogonality (no similarity). \n",
    "- To convert cosine similarity into cosine distance, you can subtract it from 1, as higher similarity should correspond to lower distance.\n",
    "The cosine distance formula is \n",
    "<img src = 'cosine for.png' height = 800 width = 550>\n",
    "consider the following example\n",
    "<img src = 'cosine exp.png' height = 800 width = 550>   \n",
    "\n",
    "## 5. Hamming distance \n",
    "- Hamming distance is mostly used in text data, which calculates the distance between two binary vectors. Here, binary vector means the data represented in the form of binary digits 0 and 1. It is also called binary strings.\n",
    "- Suppose we have two points X1 and X2 and both of them are boolean vectors, represented as:\n",
    "\n",
    "X1 = [ 0,0,0,1,0,1,1,0,1,1,1,0,0,0,1]\n",
    "\n",
    "X2 = [ 0,1,0,1,0,1,0,0,1,0,1,0,1,0,1]\n",
    "\n",
    "- So more simply the hamming distance of (X1, X2) is the location where the binary vectors or numbers are different. \n",
    "<img src = 'hamming.png' height = 800 width = 550>\n",
    "- As you see in the above image that there are 3 locations where the binary numbers are different.\n",
    "- So, we can say that the hamming distance of these two boolean vectors is 3. let’s see more mathematically.\n",
    "\n",
    "Hamming distance(X1, X2) = 3 ……… {place where binary vectors are differ}\n",
    "\n",
    "## 6. Jaccard distance\n",
    "- Jaccard similarity coefficient is used for measuring the similarity between datas sets or points. Thehigher the value of the Jaccard similarity coefficient for two sets of data, the higher is the similaritybetween them. Jaccard distance is calculated as one minus the Jaccard similarity coefficient.\n",
    "<img src='jaccard for.png' height = 800 width = 750>  \n",
    "\n",
    "&nbsp;\n",
    "[Go to Contents](#Contents)  \n",
    "  \n",
    "  \n",
    "# KNN Regression\n",
    "- For regression problem kNN algorithm is used in a way that is similar to the classification problems \n",
    "- The average of all the datapoints in a cluster or group is determined and that will our predicted output for a test datapoint.\n",
    "<img src = 'knn reg.png' height = 800 width = 650>     \n",
    "\n",
    "&nbsp;  \n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283a2b8",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "- Decision tree can be used for both classification and regression tasks. It works by building a tree-like model, where each node in the tree represents a decision and each leaf node represents a prediction.\n",
    "\n",
    "\n",
    "# Decision Tree Classification\n",
    "Decision tree for categorical features  \n",
    "  \n",
    "<img src = 'decision tree.png' heigth = 800 width = 750>      \n",
    "&nbsp;      \n",
    "\n",
    "- Decision tree algorithm uses nested if, elif, else statements to make decision or predict the final output. \n",
    "- Using decision tree algorithm we can visualize the decision tree with a few lines of code.\n",
    "    \n",
    "Consider the tennis dataset used in [naive bayes](#Naive-Bayes)\n",
    "<img src = 'decision exp.png' height = 800 width = 750>  \n",
    "\n",
    "><font color = blue> Pure split is when there is only yes and zero no's or vise versa.  \n",
    "Impure split is when there is a mixture of both yes and no's.</font>    \n",
    "  \n",
    "&nbsp;  \n",
    "- Decision tree will stop if it reaches the pure split in all branches.\n",
    "- Overcast is pure split so it has stopped. On the other hand sunny and rain is impure split therefore the tree will further go on.\n",
    "    \n",
    "&nbsp;  \n",
    "- <font color = red>**How the purity of the leaf is calculated.**</font>    \n",
    "- The purity is calculate based on two methods   \n",
    "    1. Observing how many yes and no's are there  \n",
    "    2. Using <font color = blue>Entropy and Gini impurity / Gini coefficient</font>    \n",
    "    \n",
    "## Calculation of purity\n",
    "\n",
    "## 1. Entropy\n",
    "<img src = 'purity.png' height = 800 width = 650>  \n",
    "\n",
    "## 2. Gini Impurity\n",
    "<img src = 'gini.png' height = 800 width = 650>  \n",
    "\n",
    "><font color = red>**Now the question here is which one we should use?   \n",
    "    Should we use Entropy or Gini impurity for calculating the purity?**</font>  \n",
    "    \n",
    "><font color = blue>**Entropy involves complex mathematics i.e log2.  \n",
    "    Gini impurity involves only simple mathematics.  \n",
    "    So if the dataset contains more features using entropy will take a lot of time as well as resources therefore we should go with gini impurity.\n",
    "    Similarly if the dataset contains less features we can use entropy.**</font>  \n",
    "    \n",
    "&nbsp;  \n",
    "- **The important step in decision tree algorithm is to decide which feature should we split.**\n",
    "    \n",
    "## Information Gain\n",
    "<img src = 'info gain.png' height = 800 width = 870>\n",
    "<img src = 'info gain 2.png' height = 700 width = 600>    \n",
    "  \n",
    "&nbsp;  \n",
    "[Go to Contents](#Contents)  \n",
    "  \n",
    "  \n",
    "# Decision Tree Regression\n",
    "Decision tree for continuous feature\n",
    "  \n",
    "<img src = 'decision data 2.png' heigth = 200 width = 250>\n",
    "<img src = 'decision reg2.png' height = 600 width = 550>\n",
    "  \n",
    "&nbsp;  \n",
    "Conside the following example  \n",
    "<img src = 'decision data.png' height = 200 width = 250>    \n",
    "<img src = 'decision reg1.png' height = 600 width = 550>\n",
    "\n",
    "&nbsp;  \n",
    ">**The above procedure will be followed while splitting the values of a feature.**  \n",
    "  \n",
    "><font color = red>**How do we assign the threshold value?**</font>  \n",
    "<font color = blue>**It will be based on purity and informaiton gain**</font>  \n",
    "\n",
    "## Disadvantages of Decision tree in regression problems\n",
    "1. If the feature has larger number of values the time complexity involved while splitting values will gets higher.\n",
    "2. Requires more resources and time when dealing with larger numerical dataset.\n",
    "\n",
    "\n",
    "## Hyperparameter tuning\n",
    "\n",
    "## 1. Post pruning\n",
    "<img src = 'hyper decision.png' height = 800 width = 650>\n",
    "\n",
    "## 2. Pre pruning\n",
    "- Pre pruning is decided by the following hyperparameter\n",
    "    1. max_depth\n",
    "    2. max_leaf \n",
    "- Both of which is done by GridSearch Cv.\n",
    "&nbsp;  \n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e640ca",
   "metadata": {},
   "source": [
    "# Ensemble Techniques\n",
    "- Ensemble techniques are quite different from other machine learning algorithms. \n",
    "- Usually to solve a problem whether regression or classificaiton we use any one machine learning algorithm that suits the best.\n",
    "- But that is not the case in ensemble techniques. \n",
    "- **In ensemble techniques we use multiple algorithms together to solve a problem.** The core objective here is to use a combination of algorithms to build a stronger and more accurate model with improved performance.\n",
    "<img src = 'ensemble.png' height = 900 width = 650>\n",
    "\n",
    "# Bagging \n",
    "<img src = 'bagging clas.png' height = 900 width = 750>  \n",
    "  \n",
    "><font color = red>**What if the aggregated output is in 50:50 and we don't have a majority?**</font>\n",
    "Well in real world scenarios we have more than 100 models therefore the chances of getting a 50:50 is very low.  \n",
    "\n",
    "<img src = 'bagging reg.png' height = 900 width = 750>\n",
    "\n",
    "><font color = green>**In Bagging we have parallel model.**</font>    \n",
    "  \n",
    "&nbsp;  \n",
    "# Boosting\n",
    "<img src = 'boosting.png' height = 900 width = 800>\n",
    "\n",
    "><font color = green>**In boosting the models are squenced together.**</font>  \n",
    "This is not the case in bagging.  \n",
    "\n",
    "## Algorithms used in bagging and boosting\n",
    "<img src ='bag and bos.png' height = 600 width = 700>\n",
    "\n",
    "# Bagging\n",
    "# Random Forest Classification\n",
    "- We do know that decision tree classifier is prone to overfitting therefore we need to convert the overfitting into a generalized model with the use of random forest classifier.\n",
    "<img src = 'Random F.png' height = 600 width = 600>\n",
    "<img src = 'Random F1.png' height = 600 width = 700>\n",
    "&nbsp;  \n",
    "- Random Forest is a bagging technique meaning multiple algorithms are used to build individual models and those individual models are combined to build a single more robust model.  \n",
    "- Random forest uses only decision tree algorithm in all the individual models.\n",
    "<img src = 'Random F2.png' height = 600 width = 780>\n",
    "\n",
    "><font color = blue>**1. Random forest uses decision algorithm for every model.  \n",
    "    2. Rows and features are sampled for each model individually. RF ensures that equal opportunity and chances are given for rows and features to be selected.  \n",
    "    3. Since rows and features are sampled, each model will be an expert in that specific information  \n",
    "    4. Due to overfitting in decision tree, we combine multiple models of decision tree togerther to build a more robust generalized model.**</font>    \n",
    "    \n",
    "# Random Forest Regression\n",
    "- Random forest for regression works the same way as decision tree for regression.\n",
    "<img src = 'Random F3.png' height = 600 width = 780>\n",
    "\n",
    "><font color = red>**Is normalization required in random forest?</font>  \n",
    "    No, we are only splitting the features and its values.**   \n",
    "    \n",
    "><font color = red>**Is random forest affected by outliers?</font>  \n",
    "    No.**\n",
    "    \n",
    "&nbsp;  \n",
    "[Go to Contents](#Contents)\n",
    "  \n",
    "    \n",
    "# Boosting\n",
    "# 1. Ada Boost \n",
    "# Classification and Regression\n",
    "<img src = 'ada boost 2.png' height = 800 width = 900>\n",
    "<img src = 'ada boost 5.png' height = 800 width = 900>\n",
    "<img src = 'ada boost 7.png' height = 800 width = 1000>  \n",
    "&nbsp;    \n",
    "&nbsp;    \n",
    "  \n",
    "[Go to Contents](#Contents)  \n",
    "\n",
    "# 2. Gradient Boosting \n",
    "# Classification and Regression\n",
    "<img src = 'gradient 2.png' height = 800 width = 800>\n",
    "<img src = 'gradient 3.png' height = 800 width = 800>  \n",
    "  \n",
    "&nbsp;  \n",
    "**Given below is the pseudo algorithm of gradient boosting**\n",
    "&nbsp;    \n",
    "<img src = 'gradient pseudo.png' height = 700 width = 700>\n",
    "\n",
    "&nbsp; \n",
    "For mathematical implementation refer notes.  \n",
    "&nbsp;    \n",
    "[Go to Contents](#Contents)    \n",
    "  \n",
    "# 3. XG Boost \n",
    "# XG Boost Classification\n",
    "<img src = 'xg.png' height = 800 width = 500>\n",
    "<img src = 'xg 1.png' height = 800 width = 650>\n",
    "<img src = 'xg 2.png' height = 800 width = 700>\n",
    "<img src = 'xg 4.png' height = 800 width = 700>\n",
    "\n",
    "# XG Boost Regression\n",
    "<img src = 'xg reg 2.png' height = 800 width = 700>  \n",
    "<img src = 'xg hyper.png' height = 800 width = 700>  \n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a00a8",
   "metadata": {},
   "source": [
    "# Support Vector Machine[SVM]\n",
    "-  Support vector machine can be used for both classification and regression tasks. It works by finding a hyperplane in the data that separates the different classes as widely as possible. The hyperplane is chosen in such a way that it maximizes the margin, which is the distance between the hyperplane and the closest data points from each class.\n",
    "  \n",
    "# Classification and Regression\n",
    "\n",
    "- Consider the below example\n",
    "<img src = 'SVM.png' height = 600 width = 650>  \n",
    "&nbsp;  \n",
    "\n",
    "## Hyper plane\n",
    "- <font color = red>**Hyperplane**</font> is similar to linear line (best fit). The hyperplane has to be determined in a way that separates the datapoints of different classes in a high dimensional space.\n",
    "- It is chosen in a way that maximizes the <font color = \"#FF1493\">**margin.**</font> Margin is the distance between the hyperplane and the nearest datapoints of each class.\n",
    "- The datapoint that are closer to the hyperplane are called <font color = brown>**support vectors [SV].**</font>\n",
    "\n",
    "## Marginal plane\n",
    "- While creating hyperplane two other parallel planes will also be created which is called <font color = blue>**marginal plane.**</font>  \n",
    "- All the three plane will be parallel to each other.\n",
    "- These marginal plane has to pass through one of the nearest data points.\n",
    "- One marginal plane has to pass through the nearest postitive point <font color = red>**d+**</font> / <font color=\"#9400D3\">**violet class**</font> and the other plane has to pass through the nearest negative point <font color = red>**d-**</font> / <font color=orange>**orange class**</font>.  \n",
    "\n",
    "><font color =red>What is the significance of marginal plane?</font>.\n",
    "\n",
    "In any machine learning model our motive is to create a generalized model. In a generalized model there will low bias and low variance. It has high accuracy.\n",
    "- The hyper plane separates the positive and negative datapoints.\n",
    "- The marginal plane helps in categorizing or classifing a specific datapoints\n",
    "- For a test datapoint if it falls in betweent the hyperplane and the margial plane, marginal plane helps in classifing the datapoint correctly. Marginal plane acts a threshold for classifing datapoints.\n",
    "- **Therefore the marginal plane and the margin are important.**\n",
    "<img src = 'SVM 1.png' height = 600 width = 650>\n",
    "\n",
    "## Multiple Hyperplanes \n",
    "- We can also create multiple hyper planes. Eg: in the center \n",
    "<img src = 'SVM 2.png' height = 600 width = 650>  \n",
    "comparing the two different hyperplanes i.e cross and centre, it is clear that the marginal distance for centered hyperplane is very low.  \n",
    "<font color = blue>The hyperplane has to be created in a way it maximizes the marginal distance</font>.    \n",
    "\n",
    "><font color = red>All these concepts we have seen are applicable for linearly separable datapoints only.</font>\n",
    "What if the datapoints are not linearly separable.\n",
    "  \n",
    "<img src = 'SVM 3.png' height = 600 width = 600>\n",
    "- If we draw a hyperplane crossing the datapoints (like the above graph) the accuracy will be very very low.  \n",
    "  \n",
    ">So how do we solve non linearly separable problem?    \n",
    "Using <font color = green>SVM kernals</font>    \n",
    "- The above graph is in 2D low dimensional space. SVM kernals will convert low dimension into high dimension.\n",
    "<img src = 'SVM k.png' height = 600 width = 700>  \n",
    "<img src = 'SVM k1.png' height = 600 width = 700>  \n",
    "- By Converting the data into higher dimension we were able to separate the datapoints and able to determine a proper hyperplane.  \n",
    "  \n",
    "&nbsp;    \n",
    "[Go to Contents](#Contents)    \n",
    "  \n",
    "# SVM Intution\n",
    "- The main difference between SVM and logistic regression is that in logistic regression we only create a best fit line but in SVM we create best fit line (Hyper plane) as well as marginal plane.\n",
    "- The math behind SVM helps in understanding it in a more clear way.\n",
    "<img src = 'SVM intu.png' height = 600 width = 650>  \n",
    "<img src = 'SVM margin.png' height = 600 width = 650>    \n",
    "&nbsp;    \n",
    "  \n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91f052",
   "metadata": {},
   "source": [
    "# 5. Unsupervised Machine Learning algorithms\n",
    "\n",
    "# K-means Clustering\n",
    "- K-means clustering is an unsupervised machine learning algorithm that is used to group similar data points together and discover underlying patterns. \n",
    "- It is a simple and popular algorithm that is used to divide a dataset into k number of clusters. The algorithm identifies k number of centroids and allocates every data point to the nearest cluster while keeping the centroids as small as possible.\n",
    "- The 'means' in K-means refers to averaging of the data, which is finding the centroid.\n",
    "<img src = 'k means.png' heigth = 800 width = 650>\n",
    "- In the image we do not know how many classes are there, we only know that there are 3 clusters.   \n",
    "To find the number of classes we follow a certain steps   \n",
    "\n",
    "<img src = 'k means 1.png' height = 800 width = 590>\n",
    "\n",
    "> <font color = red>**How will the k value be decided?**</font>  \n",
    "We cannot just like that assume k value. Therefore we use something called as <font color = blue>**Elbow method**</font> \n",
    "\n",
    "<img src= 'k means 2.png' height = 800 width = 670>\n",
    "\n",
    "&nbsp;    \n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e9710",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering\n",
    "- Hierarchical clustering is an unsupervised ML algorithm which used for grouping datapoints together into hierarchical clusters. The result of the hierarchical clustering is often visualized as a tree like diagram called dendrogram.\n",
    "<img src = 'h cluster.png' height = 800 width = 650>\n",
    "\n",
    "## Does K means or hierarchical clustering takes more time ?\n",
    "- Hierarchical Clustering takes more time.\n",
    "    - If dataset is small go with hierarchical clustering.\n",
    "    - If dataset if large go with k means clustering. \n",
    "- Both will take time but k means works well in large dataset compared to hierarchical clustering.\n",
    "&nbsp;  \n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e62200",
   "metadata": {},
   "source": [
    "# DB Scan\n",
    "- DB SCAN - Density based spatial clustering of application with noise.\n",
    "<img src = 'DS scan.png' height = 800 width = 610>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f8e25",
   "metadata": {},
   "source": [
    "# 6.  Dimensionality Reduction\n",
    "\n",
    "## Curse of Dimensionality\n",
    "- The curse of dimensionality is a phenomenon that occurs when the number of features in a dataset is too large it leads to a decrease in the accuracy of the model. \n",
    "- As the number of features/dimensions in a model increases above a certain extend, the accuracy of the model decreases due to overfitting, increased in computational complexity and increased data sparsity.\n",
    "\n",
    "><font color=red>**How do we avoid curse of dimensionality?**</font>  \n",
    "<font color = blue>Using Feature selection and Principle component analysis</font>  \n",
    "\n",
    "## Feature Selection\n",
    "- Feature selection as the name suggests is a technique in which we only select those features that has a stronge correlation and impact on the target feature. \n",
    "- Its a technique in which we train our model with only those features that has a strong relationship with the target feature.\n",
    "- Other features that does not has a relationship with the target feature will be neglected.\n",
    "\n",
    "## Principle Component Analysis\n",
    "- Principle component analysis is a subset of dimensionality reduction in which a new feature will be formed/derived from a set of features which are a part of the dataset. This newly derived feature will contain all the essence of those set of features which are a part of the dataset.\n",
    "- By doing so we can reduce the dimensions in the dataset and avoid overfittng.\n",
    "<img src = 'PCA.png' height = 800 width = 600>\n",
    "\n",
    "For intution of PCA refer notes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7275a133",
   "metadata": {},
   "source": [
    "# 7.  Performance Metrics\n",
    "\n",
    "# 7.1  Supervised ML Metrics\n",
    "\n",
    "# Performance Metrics for Regression Problems\n",
    "\n",
    "## $ R^2 $ and Adjusted $ R^2 $\n",
    "  - $R^2$  and adjusted $ R^2 $ are both statistical measures used to assess the goodness of fit of a regression model, particularly in linear regression. They provide insights into how well the independent variables in the model explain the variability in the dependent variable.\n",
    "  \n",
    "&nbsp;  \n",
    "## $ R^2 $\n",
    "\n",
    "<img src = 'r square.png' height = 800 width = 650>\n",
    "  \n",
    "&nbsp;  \n",
    "- SSRES - Sum of residual \n",
    "- SSTOT - Sum of total\n",
    "- $ y ̂ i $ - hθ (x) or linear line\n",
    "- $ y ¯ $ - mean of y   \n",
    "&nbsp;       \n",
    "- ($ yi - y ̂ i $) is the difference between the data points and linear line.  \n",
    "- ($ yi - y ¯ $) is the difference between the data points and mean of y.  \n",
    "  \n",
    "<img src = 'R2.jpg' height = 800 width = 650>\n",
    "\n",
    "&nbsp;  \n",
    "- $ y ̂ i $ will be a lesser value\n",
    "- $ y ¯ $ will be a higher value  \n",
    "Therefore    \n",
    "<img src = 'smaller.png' height = 600 width = 750>\n",
    "\n",
    "## Disadvantages of $ R^2 $\n",
    "\n",
    "- The main disadvantages of $ R^2 $ is as the number of features gets increased in a model no matter whether the feature has a relationship or not the $ R^2 $ will always increase.\n",
    "- The value of $ R^2 $ increases as the features (predictors) in the model increases. The value increase even if there is no relationship between the feature and target variable.\n",
    "- **$ R^2 $ does not consider the relationship between the features and the target variable.**\n",
    "<img src = 'dis of r2.png' height = 800 width = 650>  \n",
    "\n",
    "&nbsp;   \n",
    "- As the number of features increases the performance of the model increases even when there is no correlation betweent the feautre and target variable.\n",
    "\n",
    "**To solve this problem we use Adjusted $ R^2 $**\n",
    "\n",
    "# Adjusted $ R^2 $\n",
    "&nbsp;  \n",
    "<img src = 'adju r2.png' heigth = 800 width = 650>  \n",
    "- Adjusted $ R^2 $ address the drawback of $ R^2 $, it considers the relationship of independent feature when evaluting the performance of the model.\n",
    "\n",
    "&nbsp;\n",
    "<img src = 'ad per.png' height = 800 width = 750>  \n",
    "&nbsp;  \n",
    "- We can observe that the adjusted $R^2$ value decreases while adding more feature that have no correlation.\n",
    "- <font color = red> Why does 88% has been reduced to 85%? </font>  \n",
    "Because  \n",
    "<img src = 'exp adj.png' height = 800 width = 650>  \n",
    "&nbsp;  \n",
    "-  A increase in the number of features does not lead to an increase in the adjusted $R^2$ value due to change in the denominator of the formula.\n",
    "\n",
    "&nbsp;  \n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "[Go to Content](#Contents)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb33757",
   "metadata": {},
   "source": [
    "# Performance Metrics for Classification Problems\n",
    "\n",
    "## Confusion Matrix\n",
    "- Confusion matrix is used to evluate the performance of a classification model. It is a table that shows the acutal and predicted classifications of datapoints.\n",
    "- Confusion matrix is used particularly for a binary class problem.\n",
    "- It contains 4 components\n",
    "    1. True positive - The datapoint is actually positive and is correctly classified as positive.\n",
    "    2. True negative - The datapoint is actually negative and is correctly classified as negative.\n",
    "    3. False positive - The datapoint is actually negative but has been wrongly classified as positive.\n",
    "    4. False negative - The datapoint is actually positive but has been wrongly classsified as negative.  \n",
    "<img src = 'confus matri.png' height = 900 width = 850>    \n",
    "&nbsp;    \n",
    "- Confusion matrix can be used to calculate the following performance metrices\n",
    "    1. Accuracy\n",
    "    2. Precision \n",
    "    3. Recall\n",
    "    4. Specificity\n",
    "    5. F score\n",
    "    \n",
    "## 1. Accuracy  \n",
    "- Accuracy is a measure of how many predictions a classification model got correct out of the total number of predictions.\n",
    "- <font color = blue>**Measure of correct predictions out the total number of predictions.**</font>  \n",
    "<img src = 'accuracy.png' height = 800 width = 500>  \n",
    "- Suppose our dataset is imbalanced. Out of the 1000 datapoints it contains,\n",
    "    - 0's = 900\n",
    "    - 1's = 100\n",
    "    - In such scenarios the model specializes or biased over predicting 0's only. As a result 900 / 1000 = .9 i.e 90% will be the accuracy of our model which is incorrect. \n",
    "    - In such situations we should use precision, recall or F1 score.\n",
    "    \n",
    "## 2. Precision\n",
    "- Precision is a measure of the accuracy of positive predictions. It answers the question: \"Of all instances predicted as positive, how many were correctly predicted?\"\n",
    "- Also known as **positive prediction value.**\n",
    "- <font color = blue>**Focuses on reducing false positive**.</font>\n",
    "\n",
    "<img src = 'pre exp.png' height = 800 width = 760>\n",
    "<img src = 'Precision.png' height = 800 width = 500>\n",
    "\n",
    "## 3. Recall\n",
    "- Recall is a measure of the model's ability to correctly identify all positive instances. It answers the question: \"Of all actual positives, how many were correctly predicted?\"\n",
    "- Also known as **true positive rate or sensitivity.**\n",
    "- <font color = blue>**Focuses on reducing false negative.**</font>\n",
    "<img src = 'rec exp.png' height = 800 width = 700>\n",
    "<img src = 'recall.png' height = 800 width = 500>\n",
    "\n",
    "## 4. Specificity\n",
    "-  Specificity measures the accuracy of the model's ability to correctly identify negative instances out of all instances that are actually negative. It answers the question: \"Of all instances that are actually negative, how many were correctly predicted as negative?\"\n",
    "- Also known as **True negative rate**.\n",
    "<img src = 'spec exp.png' height = 800 width = 700>\n",
    "<img src = 'specificity.png' height = 800 width = 500>\n",
    "\n",
    "## 5. F1 - score\n",
    "-  The F1-Score is the harmonic mean of precision and recall. It provides a balance between the two metrics.\n",
    "- The F1-Score combines both precision and recall into a single metric. It's useful when you want to strike a balance between minimizing false positives and false negatives.\n",
    "- <font color = blue>**Focuses on reducing both false positive and false negative**</font>.\n",
    "<img src = 'F1.png' height = 800 width = 650>  \n",
    "<img src = 'F1 pre.png' height = 800 width = 650>  \n",
    "<img src = 'F1 pre 1.png' height = 800 width = 650>  \n",
    "<img src = 'F1 rec.png' heigt = 800 width = 650>\n",
    "\n",
    "&nbsp;  \n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352073f",
   "metadata": {},
   "source": [
    "# 7.2  Unsupervised ML Metrics\n",
    "\n",
    "# Performance metrix for Unsupervised ML Problems\n",
    "\n",
    "# Silhouette Score\n",
    "- The silhouette score is a metric used to evaluate the quality of clusters in unsupervised machine learning, particularly in clustering algorithms like K-means, hierarchical clustering, and DBSCAN. It measures how similar each data point in one cluster is to the data points in the same cluster compared to the nearest neighboring cluster. \n",
    "<img src = 'Silhouette.png' height = 800 width = 600>\n",
    "&nbsp;\n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1396ea6e",
   "metadata": {},
   "source": [
    "# 8.  Bias and Variance \n",
    "- Bias and variance are two types of errors that can occur in a machine learning model.\n",
    "\n",
    "## Bias\n",
    "- Bias is the difference between the average prediction of the model and the correct value which we are trying to predict. In simple terms it is the error or residual.\n",
    "- It is a measure of how well a machine learning model can capture the true underlying relationships in the training data. \n",
    "- <font color=blue>**Low bias**</font> indicates that the model is able to approximately capture the underlying pattern of the data. Low bias model captures the pattern and have <font color = green>good performance</font> on the training data and test data.\n",
    "- <font color=blue>**High bias**</font> model is too simplistic and cannot able to capture the complexity of the data. Such model tend to underfit the data and have <font color = green>poor performance</font> on both training and test data.\n",
    "&nbsp;  \n",
    "## Variance\n",
    "- Variance is a measure of how much the model's predictions vary for different training datasets. In other words, variance tells you whether your model is stable or whether it produces significantly different results when trained on different subsets of the data.\n",
    "- <font color = Blue>**Low Variance**</font> indicates that the model is more stable and produces consistent predictions across different datasets. Such models generalize well to new / unseen data.\n",
    "- <font color = Blue>**High variance**</font> indicates that the model is highly sensitive to the training data and can capture noise and random fluctuations. Models with high variance tend to overfit the data, performing well on the training data but poorly on new, unseen data.\n",
    "\n",
    "&nbsp;  \n",
    "# Underfitting and Overfitting\n",
    "  \n",
    "&nbsp;\n",
    "<img src = 'fitting.png' height = 800 widht = 650>  \n",
    "  \n",
    "&nbsp;  \n",
    "# Underfitting  \n",
    "- Underfitting refers to a problem when the model does not learn the training data. It does not captures underlying the patterns, trends in the data.\n",
    "- As a result underfitting model does not perform well on train data. Therefore the model has **high bias.**\n",
    "- Due to the simplicity of the model it approximately performs well on test, new unseen data. Therefore the underfitting model has **low variance**.\n",
    "<img src = 'under prob.png' height = 800 width = 750>\n",
    "\n",
    "### Reasons for Underfitting\n",
    "- Model is too simple.\n",
    "- Not enough data.\n",
    "- Insufficient feature.\n",
    "- Insufficient training.\n",
    "\n",
    "### Solutions for underfitting\n",
    "- Increase model complexity by adding more parameter. \n",
    "- Train on more data.\n",
    "- Perform feature engineering.\n",
    "- Increase the training iterations.  \n",
    "&nbsp;    \n",
    "# Overfitting\n",
    "- Overfitting occurs when the model learns the training data too well to the point that it captures even the noises and random fluctuations in the data.\n",
    "- The model memorizes the training data instead of learning and understanding the patterns, trends and relationship.\n",
    "- As a result overfitting model performs well on training data i.e the model has **low bias** but fails to generalize the new, unseen data (test data) i.e the model has **high variance**. \n",
    "<img src = 'prob.png' height = 800 width = 750>  \n",
    "\n",
    "### Reasons for overfitting\n",
    "- Model is too comples.\n",
    "- Too much data\n",
    "- Features overload\n",
    "\n",
    "### Solutions for overfitting\n",
    "- Reduce complexity using regularization\n",
    "- Reduce data\n",
    "- Perform feature selection / PCA\n",
    "- Early stop the model during validation when performance starts to degrade.\n",
    "\n",
    "&nbsp;  \n",
    "# Bias - Variance Tradeoff\n",
    "\n",
    "## Good fit (generalized model)\n",
    "<img src = 'bias var.png' height = 800 width = 650>  \n",
    "  \n",
    "- While building a machine learning model our motive is to avoid underfitting as well overfitting and build a good fit (generalized model). Inorder to achieve it the bias and variance must be lesser.\n",
    "- The graph signifies the point in which the bias and varince is low at the same there is optimal model complexity.\n",
    "- Out motive is to achieve bias - variance tradeoff inorder to build a good fit model.\n",
    "\n",
    "&nbsp;  \n",
    "## How to achieve bias - variance Tradeoff\n",
    "1. Good mode selection\n",
    "2. Regularization (L1 and L2)\n",
    "3. Dimensionality Reduction\n",
    "4. Ensemble methods\n",
    "\n",
    "&nbsp;  \n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "[Go to Contents](#Contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
